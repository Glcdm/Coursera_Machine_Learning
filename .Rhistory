library(knitr)
install.packages("rmarkdown")
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(rattle)
library(e1071)
setwd("C:/Users/SAMSUNG/Documents/R Working Directory/Machine Learning/")
if(!file.exists("./data")){dir.create("./data/")}
sourcefile_train<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
destfile_train<-"./data/pml-training.csv"
download.file(sourcefile_train, destfile_train)
sourcefile_test<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
destfile_test<-"./data/pml-testing.csv"
download.file(sourcefile_test, destfile_test)
#Load the data
training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""),header=TRUE)
testing<-read.csv("./data/pml-testing.csv",na.strings=c("NA",""), header=TRUE)
#We set seed to make the results of the project reproducible
set.seed(8484)
if(!file.exists("./data")){dir.create("./data/")}
sourcefile_train<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
destfile_train<-"./data/pml-training.csv"
download.file(sourcefile_train, destfile_train)
sourcefile_test<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
destfile_test<-"./data/pml-testing.csv"
download.file(sourcefile_test, destfile_test)
#Load the data
training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""),header=TRUE)
testing<-read.csv("./data/pml-testing.csv",na.strings=c("NA",""), header=TRUE)
#We set seed to make the results of the project reproducible
set.seed(8484)
a<-0 #initializing variable
#Check NA Value and take only column with less than 0.5
for (i in 1:dim(training)[2]){
a[i]<-sum(is.na(training[,i]))
b<-dim(training)[1]
}
ratios_na<-a/b
#We take only column with number of NA <0.5
test_na<-ratios_na<0.5
trainingV2<-training[,test_na]
#We remove the first column (index) so that it doesn't alter our model
trainingV2<-trainingV2[,-1]
dim(training) #19622 Raw 160 Columns
dim(trainingV2) #19622 Raw 59 Columns
#Our operation suppressed 101 dummy columns
#We split our training set in two sets, one four training and one for validation.
inTrain <- createDataPartition(y=trainingV2$classe, p=0.6, list=FALSE)
trainingV3 <- trainingV2[inTrain,]
validationV3 <- trainingV2[-inTrain,]
a<-0 #initializing variable
#Check NA Value and take only column with less than 0.5
for (i in 1:dim(training)[2]){
a[i]<-sum(is.na(training[,i]))
b<-dim(training)[1]
}
ratios_na<-a/b
#We take only column with number of NA <0.5
test_na<-ratios_na<0.5
trainingV2<-training[,test_na]
training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""),header=TRUE)
testing<-read.csv("./data/pml-testing.csv",na.strings=c("NA",""), header=TRUE)
#We set seed to make the results of the project reproducible
set.seed(8484)
training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""),header=TRUE)
sourcefile_train<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
destfile_train<-"./data/pml-training.csv"
download.file(sourcefile_train, destfile_train)
sourcefile_test<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
destfile_test<-"./data/pml-testing.csv"
download.file(sourcefile_test, destfile_test)
training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""),header=TRUE)
testing<-read.csv("./data/pml-testing.csv",na.strings=c("NA",""), header=TRUE)
#We set seed to make the results of the project reproducible
set.seed(8484)
a<-0 #initializing variable
#Check NA Value and take only column with less than 0.5
for (i in 1:dim(training)[2]){
a[i]<-sum(is.na(training[,i]))
b<-dim(training)[1]
}
ratios_na<-a/b
#We take only column with number of NA <0.5
test_na<-ratios_na<0.5
trainingV2<-training[,test_na]
trainingV2<-trainingV2[,-1]
dim(training) #19622 Raw 160 Columns
dim(trainingV2) #19622 Raw 59 Columns
inTrain <- createDataPartition(y=trainingV2$classe, p=0.6, list=FALSE)
trainingV3 <- trainingV2[inTrain,]
validationV3 <- trainingV2[-inTrain,]
fit_rf<-train(classe~., data=trainingV3, method="rf")
nsv<-nearZeroVar(training, saveMetrics=TRUE)
head(nsv)
nsv2<-subset(nsv, nzv==TRUE)
dim(nsv2)
nsv2<-subset(nsv, nzv==FALSE)
dim(nsv2)
View(nsv2)
View(nzv)
View(nsv)
View(nearZeroVar(training))
dim(subset(nsv, nzv==TRUE))
dim(subset(nsv, zeroVar==TRUE))
dim(nearZeroVar(training))
nsv2<-subset(nsv, nzv==TRUE)$nzv
View(nsv2)
nsv2<-subset(nsv, nzv==TRUE)
View(nsv2)
nearZeroVar(training)
View(nsv)
nsv<-nearZeroVar(training)
trainingv1.1<-training[,-nsv]
dim(nsv)
length(nsv)
#STEP 2
#Check NA Value and take only column with less than 0.5%
a<-0 #initializing variable
for (i in 1:dim(training.2)[2]){
a[i]<-sum(is.na(training.2[,i]))
b<-dim(training.2)[1]
}
ratios_na<-a/b
#We take only column with number of NA <0.5
test_na<-ratios_na<0.5
training.3<-training.2[,test_na]
#We remove the first column (index) so that it doesn't alter our model
trainingV2<-training.3[,-1]
training.2<-training[,-nsv]
training.2<-training[,-nsv]
#STEP 2
#Check NA Value and take only column with less than 0.5%
a<-0 #initializing variable
for (i in 1:dim(training.2)[2]){
a[i]<-sum(is.na(training.2[,i]))
b<-dim(training.2)[1]
}
ratios_na<-a/b
#We take only column with number of NA <0.5
test_na<-ratios_na<0.5
training.3<-training.2[,test_na]
trainingV2<-training.3[,-1]
dim(training) #19622 Raw 160 Columns
dim(trainingV2) #19622 Raw 59 Columns
fit_rpart<-train(classe~., data=trainingV3, method="rpart")
#We plot the tree
fancyRpartPlot(fit_rpart$finalModel)
#We use our model to predict on our testing set
predict_rpart<-predict(fit_rpart, newdata=validationV3 )
confusionMatrix(predict_rpart,validationV3$classe)
par(mar)
par()$mar
par(mar=c(1,1,1,1))
fancyRpartPlot(fit_rpart$finalModel)
fit_rf<-train(classe~., data=trainingV3, method="rf")
fit_rf<-train(classe~., data=trainingV3, method="rf")
fit_rf<-randomForest(classe~., data=trainingV3)
predict_rf<-predict(fit_rf, newdata=validationV3 )
confusionMatrix(predict_rf,validationV3$classe)
fit_rpart<-train(classe~., data=trainingV3, method="class")
fit_rpart<-rpart(classe~., data=trainingV3, method="class")
fancyRpartPlot(fit_rpart$finalModel)
predict_rpart<-predict(fit_rpart, newdata=validationV3 )
confusionMatrix(predict_rpart,validationV3$classe)
fit_rpart<-predict(classe~., data=trainingV3, method="rpart", type="class")
fit_rpart<-predict(classe~., data=trainingV3,  type="class")
fit_rpart<-predict(classe~., data=trainingV3,  method="class")
fit_rpart<-predict(classe~., data=trainingV3,  method="rpart")
fit_rpart<-train(classe~., data=trainingV3, method="class")
?train
?rpart
fit_rpart<-rpart(classe~., data=trainingV3, method="class")
fancyRpartPlot(fit_rpart$finalModel)
fancyRpartPlot(fit_rpart)
confusionMatrix(predict_rpart,validationV3$classe)
predict_rpart<-predict(fit_rpart, newdata=validationV3 )
confusionMatrix(predict_rpart,validationV3$classe)
predict_rpart<-predict(fit_rpart, newdata=validationV3,type='class' )
confusionMatrix(predict_rpart,validationV3$classe)
plot(fit_rpart)
plot(fit_rf)
plot(fit_rf)
xlab("Nb of trees")
plot(fit_rf)
plot(fit_rf, xlab="Nb of Trees")
qplot(fit_rf)
qplot(fit_rf)
library(ggplot2)
qplot(fit_rf)
plot(fit_rf)
plot(fit_rf, xlab="Nb of Trees")
fit_rf<-randomForest(classe~., data=trainingV3, type='class')
plot(fit_rf, xlab="Nb of Trees")
plot(fit_rf)
plot(fit_rf, main='error in x')
plot(fit_rf, main='error in x', xlab='toto')
fit_rf
str(fit_rf)
predict_rf<-predict(fit_rf, newdata=validationV3 , type='class')
fit_rf<-randomForest(classe~., data=trainingV3)
plot(fit_rf)
plot(fit_rf$err.rate)
plot(fit_rf, main='Error (y axe) by nb Tree (x axe per 100)')
160-43
-1
117-1
plot(fit_rf)
fit_rf$err.rate
prot(fit_rf$err.rate)
fit_rf$summary
fit_rf
confusionMatrix(predict_rpart,validationV3$classe)
confusionMatrix(predict_rf,validationV3$classe)
predict_rf_real <-predict(fit_rf, newdata=testing, type='class')
testing
View(testing)
dim(testing)
dim(training)
View(head(testing,20))
View(head(training,20))
str(training)
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
testing.2<-testing[,-nsv]
testing.3<-testing.2[,-nsv]
testingV2<-testing.3[,-1]
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
dim(testingV2)
dim(training.2)
dim(testing.2)
dim(testing.3)
dim(training.3)
testing.3<-testing.2[,test_na]
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
testing.3<-testing.2[,test_na]
dim(training.3)
dim(testing.3)
View(testingV2)
names(testingV2)
names(trainingV2)
dim(trainingV2)
dim(testingV2)
testingV2<-testing.3[,-1]
names(testingV2)
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
dim(trainingV2)
names(trainingV2)
names(testinfgV2)
names(testingV2)
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
names(trainingV3)
names(trainingV2)
trainingV3 <- trainingV2[inTrain,]
inTrain <- createDataPartition(y=trainingV2$classe, p=0.6, list=FALSE)
trainingV3 <- trainingV2[inTrain,]
validationV3 <- trainingV2[-inTrain,]
names(trainingV3)
fit_rf<-randomForest(classe~., data=trainingV3)
predict_rf<-predict(fit_rf, newdata=validationV3, type='class')
predict_rf_real <-predict(fit_rf, newdata=testingV2, type='class')
names(trainingV3)
names(testingV2)
colnames(trainingV3)
colnames(trainingV3[,1:57])
testing[colnames(trainingV3[,1:57])
;
View(testing[colnames(trainingV3[,1:57])]
)
testingV3<-testing[colnames(trainingV3[,1:57])]
predict_rf_real <-predict(fit_rf, newdata=testingV3, type='class')
str(testingV3)
dim(testingV3)
dim(trainingV3)
str(trainingV3)
levels(testingv3)<-levels(trainingV3)
levels(testingv3$cvtd_timestamp)<-levels(trainingV3$cvtd_timestamp)
levels(testingV3$cvtd_timestamp)<-levels(trainingV3$cvtd_timestamp)
predict_rf_real <-predict(fit_rf, newdata=testingV3, type='class')
predict_rf
predict_rf_real
write.csv(predict_rf_real,file='ouput_project.csv')
